{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_IMDB-29122020.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMg3m0LNWLYoZtkzDFaK3EZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhijeet06793/MNIST_DL/blob/master/LSTM_IMDB_29122020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heduGzMBHW8R"
      },
      "source": [
        "#LSTM for sequence classification in the IMDB dataset\r\n",
        "import numpy\r\n",
        "from tensorflow.keras.datasets import imdb\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import LSTM\r\n",
        "from tensorflow.keras.layers import Embedding\r\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHEl5R0fHltN",
        "outputId": "965b1049-a9fe-4ae9-c64c-073e4780ce22"
      },
      "source": [
        "#Refer: https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification\r\n",
        "\r\n",
        "# load the dataset but only keep the top n words, zero the rest\r\n",
        "\r\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=5000)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vef6HUtPILVN",
        "outputId": "6a974a90-5533-42d0-9db1-83a8561ec7c8"
      },
      "source": [
        "print(x_train[1])\r\n",
        "print(type(x_train[1]))\r\n",
        "print(len(x_train[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
            "<class 'list'>\n",
            "189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvnQhfwIIZhZ",
        "outputId": "e1126558-044a-4cf2-8d55-3842b6ff725a"
      },
      "source": [
        "print(len(x_train))\r\n",
        "#cheking the largest length of text\r\n",
        "len_text = 0\r\n",
        "for i in x_train:\r\n",
        "    len_i = len(i)\r\n",
        "    if len_i>len_text:\r\n",
        "        len_text = len_i\r\n",
        "    else:\r\n",
        "        pass\r\n",
        "print(\"The text with max length is :\",len_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n",
            "The text with max length is : 2494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixWDuQdeIdn8",
        "outputId": "89249778-cb79-4867-d309-5def2432d64f"
      },
      "source": [
        "#truncating and padding the input sequences- when its greater than 600 then truncate and less than 600 then pad\r\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=600)\r\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=600)\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(x_train[1]) #Each of the 600 represent a word / timestep"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 600)\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    1  194 1153  194    2   78  228    5    6\n",
            " 1463 4369    2  134   26    4  715    8  118 1634   14  394   20   13\n",
            "  119  954  189  102    5  207  110 3103   21   14   69  188    8   30\n",
            "   23    7    4  249  126   93    4  114    9 2300 1523    5  647    4\n",
            "  116    9   35    2    4  229    9  340 1322    4  118    9    4  130\n",
            " 4901   19    4 1002    5   89   29  952   46   37    4  455    9   45\n",
            "   43   38 1543 1905  398    4 1649   26    2    5  163   11 3215    2\n",
            "    4 1153    9  194  775    7    2    2  349 2637  148  605    2    2\n",
            "   15  123  125   68    2    2   15  349  165 4362   98    5    4  228\n",
            "    9   43    2 1157   15  299  120    5  120  174   11  220  175  136\n",
            "   50    9 4373  228    2    5    2  656  245 2350    5    4    2  131\n",
            "  152  491   18    2   32    2 1212   14    9    6  371   78   22  625\n",
            "   64 1382    9    8  168  145   23    4 1690   15   16    4 1355    5\n",
            "   28    6   52  154  462   33   89   78  285   16  145   95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRk4nDoKIjSX"
      },
      "source": [
        "Embedding \r\n",
        "\r\n",
        "It must specify 3 arguments:\r\n",
        "\r\n",
        "1. input_dim: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\r\n",
        "\r\n",
        "2. output_dim: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\r\n",
        "\r\n",
        "3. input_length: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdd808dAIozJ",
        "outputId": "57adb626-80f9-4e05-fff0-ab195c3898db"
      },
      "source": [
        "#Creating the Embedding model\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(input_dim=5001, output_dim=32, input_length=600))\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 600, 32)           160032    \n",
            "=================================================================\n",
            "Total params: 160,032\n",
            "Trainable params: 160,032\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUuQUK4wIvMP"
      },
      "source": [
        "model.compile('adam', 'mse')\r\n",
        "output = model.predict(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwQEUI89IzTC",
        "outputId": "5133cc48-f2be-4e70-91b2-56ff2bc83af3"
      },
      "source": [
        "print(\"one of the text out of 25000 datapoints. Each text has shape 600*32\")\r\n",
        "print(\"Here 600 denote the words in each text and for each word is 32 length vector.\")\r\n",
        "print(\"\\n\")\r\n",
        "output[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one of the text out of 25000 datapoints. Each text has shape 600*32\n",
            "Here 600 denote the words in each text and for each word is 32 length vector.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0115489 , -0.04691615, -0.03009492, ..., -0.03648385,\n",
              "        -0.03414784, -0.03573573],\n",
              "       [-0.0115489 , -0.04691615, -0.03009492, ..., -0.03648385,\n",
              "        -0.03414784, -0.03573573],\n",
              "       [-0.0115489 , -0.04691615, -0.03009492, ..., -0.03648385,\n",
              "        -0.03414784, -0.03573573],\n",
              "       ...,\n",
              "       [ 0.04121989,  0.008472  , -0.01587288, ..., -0.01135872,\n",
              "        -0.03969252, -0.02122235],\n",
              "       [-0.00437443, -0.03417267,  0.00790776, ...,  0.02677799,\n",
              "         0.03655158,  0.02926923],\n",
              "       [ 0.01567816,  0.02356943, -0.00992377, ...,  0.02278222,\n",
              "        -0.03983846,  0.02500716]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp15ukE_JvPa",
        "outputId": "c6a8074a-617e-47c9-bf2a-7b1b1a8b9057"
      },
      "source": [
        "#Creating the model\r\n",
        "model_lstm = Sequential()\r\n",
        "model_lstm.add(Embedding(input_dim=5001, output_dim=32, input_length=600))\r\n",
        "model_lstm.add(LSTM(units=100, use_bias=False)) \r\n",
        "# Here units represent the number of neurons in each of the 4 layers (3 sig and 1 tanh) inside the LSTM cell. There is only one LSTM cell.\r\n",
        "model_lstm.add(Dense(units=1, activation='softmax'))\r\n",
        "model_lstm.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 600, 32)           160032    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               52800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 212,933\n",
            "Trainable params: 212,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhwOWqedRI25",
        "outputId": "b2a6ab27-d403-4085-b27e-fb9287e61e7a"
      },
      "source": [
        "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\r\n",
        "model_lstm.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "176/176 [==============================] - 166s 929ms/step - loss: 0.6400 - accuracy: 0.5020 - val_loss: 0.4024 - val_accuracy: 0.4876\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 159s 903ms/step - loss: 0.3362 - accuracy: 0.5006 - val_loss: 0.3802 - val_accuracy: 0.4876\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 153s 872ms/step - loss: 0.2676 - accuracy: 0.4989 - val_loss: 0.3387 - val_accuracy: 0.4876\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 157s 893ms/step - loss: 0.2669 - accuracy: 0.5003 - val_loss: 0.3457 - val_accuracy: 0.4876\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 160s 907ms/step - loss: 0.2055 - accuracy: 0.5065 - val_loss: 0.3359 - val_accuracy: 0.4876\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 155s 882ms/step - loss: 0.1786 - accuracy: 0.4998 - val_loss: 0.3411 - val_accuracy: 0.4876\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 154s 873ms/step - loss: 0.2061 - accuracy: 0.4996 - val_loss: 0.3748 - val_accuracy: 0.4876\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 154s 875ms/step - loss: 0.1696 - accuracy: 0.5029 - val_loss: 0.3759 - val_accuracy: 0.4876\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 155s 880ms/step - loss: 0.1524 - accuracy: 0.5008 - val_loss: 0.3945 - val_accuracy: 0.4876\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 159s 901ms/step - loss: 0.1574 - accuracy: 0.5026 - val_loss: 0.3874 - val_accuracy: 0.4876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5c85e7d1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}